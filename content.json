{"meta":{"title":"lizhewei'Blog","subtitle":"","description":"专注于云原生领域","author":"lizhewei","url":"http://lizhewei91.github.io","root":"/"},"pages":[{"title":"分类","date":"2022-11-25T04:13:14.000Z","updated":"2022-11-25T04:15:44.664Z","comments":true,"path":"categories/index.html","permalink":"http://lizhewei91.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-11-25T04:12:57.000Z","updated":"2022-11-25T04:15:16.176Z","comments":true,"path":"tags/index.html","permalink":"http://lizhewei91.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"NVIDIA/kubevirt-gpu-device-plugin源码分析","slug":"kubevirt-gpu-device-plugin","date":"2023-01-10T08:38:32.000Z","updated":"2023-01-11T09:41:19.478Z","comments":true,"path":"2023/01/10/32/","link":"","permalink":"http://lizhewei91.github.io/2023/01/10/32/","excerpt":"","text":"NVIDIA K8s Device Plugin为Kubevirt虚拟机分配gpu和vgpu，该篇文章基于NVIDIA/kubevirt-gpu-device-plugin:v1.2.1，https://github.com/NVIDIA/kubevirt-gpu-device-plugin/tree/v1.2.1 kubevirt-gpu-device-plugin启动还是一样的套路，一切从main.go开始 Kubevirt-gpu-device-plugin/cmd/main.go#33 func main() &#123; device_plugin.InitiateDevicePlugin()&#125; main函数调用 InitiateDevicePlugin 函数，直接看 InitiateDevicePlugin Kubevirt-gpu-device-plugin/pkg/device_plugin/device_plugin.go#73 func InitiateDevicePlugin() &#123; //Identifies GPUs and represents it in appropriate structures createIommuDeviceMap() //Identifies vGPUs and represents it in appropriate structures createVgpuIDMap() //Creates and starts device plugin createDevicePlugins()&#125; InitiateDevicePlugin 函数主要做三件事： 发现所有加载了 VFIO-PCI 驱动程序的 Nvidia gpu，并创建相应的映射 发现节点上配置的所有 Nvidia vgpu，并创建相应的映射 创建并启动 device-plugin CreateIommuDeviceMapKubevirt-gpu-device-plugin/pkg/device-plugin/device-plugin.go#155 // Discovers all Nvidia GPUs which are loaded with VFIO-PCI driver and creates corresponding mapsfunc createIommuDeviceMap() &#123; iommuMap = make(map[string][]NvidiaGpuDevice) deviceMap = make(map[string][]string) //Walk directory to discover pci devices filepath.Walk(basePath, func(path string, info os.FileInfo, err error) error &#123; if err != nil &#123; log.Printf(&quot;Error accessing file path %q: %v\\n&quot;, path, err) return err &#125; if info.IsDir() &#123; log.Println(&quot;Not a device, continuing&quot;) return nil &#125; //Retrieve vendor for the device vendorID, err := readIDFromFile(basePath, info.Name(), &quot;vendor&quot;) if err != nil &#123; log.Println(&quot;Could not get vendor ID for device &quot;, info.Name()) return nil &#125; //Nvidia vendor id is &quot;10de&quot;. Proceed if vendor id is 10de if vendorID == &quot;10de&quot; &#123; log.Println(&quot;Nvidia device &quot;, info.Name()) //Retrieve iommu group for the device driver, err := readLink(basePath, info.Name(), &quot;driver&quot;) if err != nil &#123; log.Println(&quot;Could not get driver for device &quot;, info.Name()) return nil &#125; if driver == &quot;vfio-pci&quot; &#123; iommuGroup, err := readLink(basePath, info.Name(), &quot;iommu_group&quot;) if err != nil &#123; log.Println(&quot;Could not get IOMMU Group for device &quot;, info.Name()) return nil &#125; log.Println(&quot;Iommu Group &quot; + iommuGroup) _, exists := iommuMap[iommuGroup] if !exists &#123; deviceID, err := readIDFromFile(basePath, info.Name(), &quot;device&quot;) if err != nil &#123; log.Println(&quot;Could get deviceID for PCI address &quot;, info.Name()) return nil &#125; log.Printf(&quot;Device Id %s&quot;, deviceID) deviceMap[deviceID] = append(deviceMap[deviceID], iommuGroup) &#125; iommuMap[iommuGroup] = append(iommuMap[iommuGroup], NvidiaGpuDevice&#123;info.Name()&#125;) &#125; &#125; return nil &#125;)&#125; createIommuDeviceMap的主要流程如下图： CreateVgpuIDMapKubevirt-gpu-device-plugin/pkg/device-plugin/device-plugin.go#208 // Discovers all Nvidia vGPUs configured on a node and creates corresponding mapsfunc createVgpuIDMap() &#123; vGpuMap = make(map[string][]NvidiaGpuDevice) gpuVgpuMap = make(map[string][]string) //Walk directory to discover vGPU devices filepath.Walk(vGpuBasePath, func(path string, info os.FileInfo, err error) error &#123; if err != nil &#123; log.Printf(&quot;Error accessing file path %q: %v\\n&quot;, path, err) return err &#125; if info.IsDir() &#123; log.Println(&quot;Not a device, continuing&quot;) return nil &#125; //Read vGPU type name vGpuID, err := readVgpuIDFromFile(vGpuBasePath, info.Name(), &quot;mdev_type/name&quot;) if err != nil &#123; log.Println(&quot;Could not get vGPU type identifier for device &quot;, info.Name()) return nil &#125; //Retrieve the gpu ID for this vGPU gpuID, err := readGpuIDForVgpu(vGpuBasePath, info.Name()) if err != nil &#123; log.Println(&quot;Could not get vGPU type identifier for device &quot;, info.Name()) return nil &#125; log.Printf(&quot;Gpu id is %s&quot;, gpuID) log.Printf(&quot;Vgpu id is %s&quot;, vGpuID) gpuVgpuMap[gpuID] = append(gpuVgpuMap[gpuID], info.Name()) vGpuMap[vGpuID] = append(vGpuMap[vGpuID], NvidiaGpuDevice&#123;info.Name()&#125;) return nil &#125;)&#125; 通过filePath.Walk遍历“/sys/bus/mdev/devices”目录下的所有文件，得到所有 vgpu 相应设备文件 读取readVgpuIDFromFile(“/sys/bus/mdev/devices”,info.Name(),”mdev_type/name”)，获得vgpu的vGpuID 读取readGpuIDFromVgpu(“/sys/bus/mdev/devices”,info.Name())，获取vgpu对应的gpuID 最后，通过 gpuVgpuMap=map[ ] []string{ ,…} 和 vGpuMap=map[ ] []NvidiaGpuDevice{ {addr:},{addr:}} 存储映射关系。 CreateDevicePluginsKubevirt-gpu-device-plugin/pkg/device-plugin/device-plugin.go#82 // Starts gpu pass through and vGPU device pluginfunc createDevicePlugins() &#123; var devicePlugins []*GenericDevicePlugin var vGpuDevicePlugins []*GenericVGpuDevicePlugin var devs []*pluginapi.Device log.Printf(&quot;Iommu Map %s&quot;, iommuMap) log.Printf(&quot;Device Map %s&quot;, deviceMap) log.Println(&quot;vGPU Map &quot;, vGpuMap) log.Println(&quot;GPU vGPU Map &quot;, gpuVgpuMap) //Iterate over deivceMap to create device plugin for each type of GPU on the host for k, v := range deviceMap &#123; devs = nil for _, dev := range v &#123; devs = append(devs, &amp;pluginapi.Device&#123; ID: dev, Health: pluginapi.Healthy, &#125;) &#125; deviceName := getDeviceName(k) if deviceName == &quot;&quot; &#123; log.Printf(&quot;Error: Could not find device name for device id: %s&quot;, k) deviceName = k &#125; log.Printf(&quot;DP Name %s&quot;, deviceName) dp := NewGenericDevicePlugin(deviceName, &quot;/sys/kernel/iommu_groups/&quot;, devs) err := startDevicePlugin(dp) if err != nil &#123; log.Printf(&quot;Error starting %s device plugin: %v&quot;, dp.deviceName, err) &#125; else &#123; devicePlugins = append(devicePlugins, dp) &#125; &#125; //Iterate over vGpuMap to create device plugin for each type of vGPU on the host for k, v := range vGpuMap &#123; devs = nil for _, dev := range v &#123; devs = append(devs, &amp;pluginapi.Device&#123; ID: dev.addr, Health: pluginapi.Healthy, &#125;) &#125; deviceName := getDeviceName(k) if deviceName == &quot;&quot; &#123; deviceName = k &#125; log.Printf(&quot;DP Name %s&quot;, deviceName) dp := NewGenericVGpuDevicePlugin(deviceName, vGpuBasePath, devs) err := startVgpuDevicePlugin(dp) if err != nil &#123; log.Printf(&quot;Error starting %s device plugin: %v&quot;, dp.deviceName, err) &#125; else &#123; vGpuDevicePlugins = append(vGpuDevicePlugins, dp) &#125; &#125; &lt;-stop log.Printf(&quot;Shutting down device plugin controller&quot;) for _, v := range devicePlugins &#123; v.Stop() &#125;&#125; createDevicePlugin的流程图如下： 启动kubevirt-gpu-device-plugin步骤主要有以下几点： 遍历 deviveMap 将所有 device 设备类型下的所有 gpu 标记为 healthy remove 并重建 socket 文件（”/var/lib/kubelet/device-plugins”+”kubevirt-.sock”） 启动 devicePlugin 的 grpc server，对外提供服务 请求kubelet socket链接，进行Regster 启动一个协程对设备进行healthCheck，并监听device-plguin自身socket文件 总结kubevirt-gpu-device-plugin使用前提，是用户使用 vfio-pci 将设备透传至 vm 内，然后，通过读取 vm 内的 pci 设备文件，获取设备的相关信息。iommu,vfio-pci等相关的内容，后续有时间会再补充。","categories":[{"name":"device-plugins","slug":"device-plugins","permalink":"http://lizhewei91.github.io/categories/device-plugins/"}],"tags":[{"name":"device-plugins","slug":"device-plugins","permalink":"http://lizhewei91.github.io/tags/device-plugins/"},{"name":"gpu","slug":"gpu","permalink":"http://lizhewei91.github.io/tags/gpu/"},{"name":"kubevirt-gpu-device-plugin","slug":"kubevirt-gpu-device-plugin","permalink":"http://lizhewei91.github.io/tags/kubevirt-gpu-device-plugin/"}]},{"title":"NVIDIA/k8s-device-plugin源码分析","slug":"nvidia-device-plugin","date":"2023-01-06T07:43:46.000Z","updated":"2023-01-10T09:08:02.649Z","comments":true,"path":"2023/01/06/46/","link":"","permalink":"http://lizhewei91.github.io/2023/01/06/46/","excerpt":"","text":"device-plugin启动该篇文章基于NVIDIA/k8s-device-plugin: v0.13.0，https://github.com/NVIDIA/k8s-device-plugin/tree/v0.13.0 一切从 main 函数开始作为入口： k8s-device-plugin/cmd/nvidia-device-plugin/main.go#35 func main() &#123; var configFile string c := cli.NewApp() c.Name = &quot;NVIDIA Device Plugin&quot; c.Usage = &quot;NVIDIA device plugin for Kubernetes&quot; c.Version = info.GetVersionString() c.Action = func(ctx *cli.Context) error &#123; return start(ctx, c.Flags) ... &#125; 接下来，调用 start 函数 k8s-device-plugin/cmd/nvidia-device-plugin/main.go#133 func start(c *cli.Context, flags []cli.Flag) error &#123; log.Println(&quot;Starting FS watcher.&quot;) watcher, err := newFSWatcher(pluginapi.DevicePluginPath) if err != nil &#123; return fmt.Errorf(&quot;failed to create FS watcher: %v&quot;, err) &#125; defer watcher.Close() log.Println(&quot;Starting OS watcher.&quot;) sigs := newOSWatcher(syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT) var restarting bool var restartTimeout &lt;-chan time.Time var plugins []*NvidiaDevicePluginrestart: // If we are restarting, stop plugins from previous run. if restarting &#123; err := stopPlugins(plugins) if err != nil &#123; return fmt.Errorf(&quot;error stopping plugins from previous run: %v&quot;, err) &#125; &#125; log.Println(&quot;Starting Plugins.&quot;) plugins, restartPlugins, err := startPlugins(c, flags, restarting) if err != nil &#123; return fmt.Errorf(&quot;error starting plugins: %v&quot;, err) &#125; if restartPlugins &#123; log.Printf(&quot;Failed to start one or more plugins. Retrying in 30s...&quot;) restartTimeout = time.After(30 * time.Second) &#125; restarting = true // Start an infinite loop, waiting for several indicators to either log // some messages, trigger a restart of the plugins, or exit the program. for &#123; select &#123; // If the restart timout has expired, then restart the plugins case &lt;-restartTimeout: goto restart // Detect a kubelet restart by watching for a newly created // &#x27;pluginapi.KubeletSocket&#x27; file. When this occurs, restart this loop, // restarting all of the plugins in the process. case event := &lt;-watcher.Events: if event.Name == pluginapi.KubeletSocket &amp;&amp; event.Op&amp;fsnotify.Create == fsnotify.Create &#123; log.Printf(&quot;inotify: %s created, restarting.&quot;, pluginapi.KubeletSocket) goto restart &#125; // Watch for any other fs errors and log them. case err := &lt;-watcher.Errors: log.Printf(&quot;inotify: %s&quot;, err) // Watch for any signals from the OS. On SIGHUP, restart this loop, // restarting all of the plugins in the process. On all other // signals, exit the loop and exit the program. case s := &lt;-sigs: switch s &#123; case syscall.SIGHUP: log.Println(&quot;Received SIGHUP, restarting.&quot;) goto restart default: log.Printf(&quot;Received signal \\&quot;%v\\&quot;, shutting down.&quot;, s) goto exit &#125; &#125; &#125;exit: err = stopPlugins(plugins) if err != nil &#123; return fmt.Errorf(&quot;error stopping plugins: %v&quot;, err) &#125; return nil&#125; Startk8s-device-plugin/cmd/nvidia-device-plugin/server.go#92 K8s-device-plugin的启动流程中，nvidiaDevicePlugin.Start主要有三个步骤，1.启动device-plugin的grpc服务；2.向kubelet注册；3.启动协程对设备checkHealth。 func (plugin *NvidiaDevicePlugin) Start() error &#123; plugin.initialize() err := plugin.Serve() if err != nil &#123; log.Printf(&quot;Could not start device plugin for &#x27;%s&#x27;: %s&quot;, plugin.rm.Resource(), err) plugin.cleanup() return err &#125; log.Printf(&quot;Starting to serve &#x27;%s&#x27; on %s&quot;, plugin.rm.Resource(), plugin.socket) err = plugin.Register() if err != nil &#123; log.Printf(&quot;Could not register device plugin: %s&quot;, err) plugin.Stop() return err &#125; log.Printf(&quot;Registered device plugin for &#x27;%s&#x27; with Kubelet&quot;, plugin.rm.Resource()) go func() &#123; err := plugin.rm.CheckHealth(plugin.stop, plugin.health) if err != nil &#123; log.Printf(&quot;Failed to start health check: %v; continuing with health checks disabled&quot;, err) &#125; &#125;() return nil&#125; Servek8s-device-plugin/cmd/nvidia-device-plugin/server.go#136 k8s-device-plugin 启动 gRPC 服务，对外提供服务 func (plugin *NvidiaDevicePlugin) Serve() error &#123; os.Remove(plugin.socket) sock, err := net.Listen(&quot;unix&quot;, plugin.socket) if err != nil &#123; return err &#125; pluginapi.RegisterDevicePluginServer(plugin.server, plugin) go func() &#123; lastCrashTime := time.Now() restartCount := 0 for &#123; log.Printf(&quot;Starting GRPC server for &#x27;%s&#x27;&quot;, plugin.rm.Resource()) err := plugin.server.Serve(sock) if err == nil &#123; break &#125; log.Printf(&quot;GRPC server for &#x27;%s&#x27; crashed with error: %v&quot;, plugin.rm.Resource(), err) // restart if it has not been too often // i.e. if server has crashed more than 5 times and it didn&#x27;t last more than one hour each time if restartCount &gt; 5 &#123; // quit log.Fatalf(&quot;GRPC server for &#x27;%s&#x27; has repeatedly crashed recently. Quitting&quot;, plugin.rm.Resource()) &#125; timeSinceLastCrash := time.Since(lastCrashTime).Seconds() lastCrashTime = time.Now() if timeSinceLastCrash &gt; 3600 &#123; // it has been one hour since the last crash.. reset the count // to reflect on the frequency restartCount = 1 &#125; else &#123; restartCount++ &#125; &#125; &#125;() // Wait for server to start by launching a blocking connexion conn, err := plugin.dial(plugin.socket, 5*time.Second) if err != nil &#123; return err &#125; conn.Close() return nil&#125; serve主要负责重建nvidia.sock文件，并且注册5个grpc接口到grpc.Server。 Registerk8s-device-plugin/cmd/nvidia-device-plugin/server.go#186 Serve之后，接着进入Register流程，其代码如下： func (plugin *NvidiaDevicePlugin) Register() error &#123; conn, err := plugin.dial(pluginapi.KubeletSocket, 5*time.Second) if err != nil &#123; return err &#125; defer conn.Close() client := pluginapi.NewRegistrationClient(conn) reqt := &amp;pluginapi.RegisterRequest&#123; Version: pluginapi.Version, Endpoint: path.Base(plugin.socket), ResourceName: string(plugin.rm.Resource()), Options: &amp;pluginapi.DevicePluginOptions&#123; GetPreferredAllocationAvailable: true, &#125;, &#125; _, err = client.Register(context.Background(), reqt) if err != nil &#123; return err &#125; return nil&#125; Register的实现流程图如下： 注册的Resource Name是nvidia.com/gpu 注册的Version是v1beta1 CheckHealthk8s-device-plugin/internal/rm/health.go#42 启动协程开始对管理的devices进行健康状态空空，一旦发现有device unhealthy，则发送到NvidiaDevicePlugin的health channel。 func (r *nvmlResourceManager) checkHealth(stop &lt;-chan interface&#123;&#125;, devices Devices, unhealthy chan&lt;- *Device) error &#123; disableHealthChecks := strings.ToLower(os.Getenv(envDisableHealthChecks)) if disableHealthChecks == &quot;all&quot; &#123; disableHealthChecks = allHealthChecks &#125; if strings.Contains(disableHealthChecks, &quot;xids&quot;) &#123; return nil &#125; ret := r.nvml.Init() if ret != nvml.SUCCESS &#123; if *r.config.Flags.FailOnInitError &#123; return fmt.Errorf(&quot;failed to initialize NVML: %v&quot;, ret) &#125; return nil &#125; defer func() &#123; ret := r.nvml.Shutdown() if ret != nvml.SUCCESS &#123; log.Printf(&quot;Error shutting down NVML: %v&quot;, ret) &#125; &#125;() // FIXME: formalize the full list and document it. // http://docs.nvidia.com/deploy/xid-errors/index.html#topic_4 // Application errors: the GPU should still be healthy applicationErrorXids := []uint64&#123; 13, // Graphics Engine Exception 31, // GPU memory page fault 43, // GPU stopped processing 45, // Preemptive cleanup, due to previous errors 68, // Video processor exception &#125; skippedXids := make(map[uint64]bool) for _, id := range applicationErrorXids &#123; skippedXids[id] = true &#125; for _, additionalXid := range getAdditionalXids(disableHealthChecks) &#123; skippedXids[additionalXid] = true &#125; eventSet, ret := r.nvml.EventSetCreate() if ret != nvml.SUCCESS &#123; return fmt.Errorf(&quot;failed to create event set: %v&quot;, ret) &#125; defer eventSet.Free() parentToDeviceMap := make(map[string]*Device) deviceIDToGiMap := make(map[string]int) deviceIDToCiMap := make(map[string]int) eventMask := uint64(nvml.EventTypeXidCriticalError | nvml.EventTypeDoubleBitEccError | nvml.EventTypeSingleBitEccError) for _, d := range devices &#123; uuid, gi, ci, err := r.getDevicePlacement(d) if err != nil &#123; log.Printf(&quot;Warning: could not determine device placement for %v: %v; Marking it unhealthy.&quot;, d.ID, err) unhealthy &lt;- d continue &#125; deviceIDToGiMap[d.ID] = gi deviceIDToCiMap[d.ID] = ci parentToDeviceMap[uuid] = d gpu, ret := r.nvml.DeviceGetHandleByUUID(uuid) if ret != nvml.SUCCESS &#123; log.Printf(&quot;unable to get device handle from UUID: %v; marking it as unhealthy&quot;, ret) unhealthy &lt;- d continue &#125; supportedEvents, ret := gpu.GetSupportedEventTypes() if ret != nvml.SUCCESS &#123; log.Printf(&quot;unabled to determine the supported events for %v: %v; marking it as unhealthy&quot;, d.ID, ret) unhealthy &lt;- d continue &#125; ret = gpu.RegisterEvents(eventMask&amp;supportedEvents, eventSet) if ret == nvml.ERROR_NOT_SUPPORTED &#123; log.Printf(&quot;Warning: Device %v is too old to support healthchecking.&quot;, d.ID) &#125; if ret != nvml.SUCCESS &#123; log.Printf(&quot;Marking device %v as unhealthy: %v&quot;, d.ID, ret) unhealthy &lt;- d &#125; &#125; for &#123; select &#123; case &lt;-stop: return nil default: &#125; e, ret := eventSet.Wait(5000) if ret == nvml.ERROR_TIMEOUT &#123; continue &#125; if ret != nvml.SUCCESS &#123; log.Printf(&quot;Error waiting for event: %v; Marking all devices as unhealthy&quot;, ret) for _, d := range devices &#123; unhealthy &lt;- d &#125; continue &#125; if e.EventType != nvml.EventTypeXidCriticalError &#123; log.Printf(&quot;Skipping non-nvmlEventTypeXidCriticalError event: %+v&quot;, e) continue &#125; if skippedXids[e.EventData] &#123; log.Printf(&quot;Skipping event %+v&quot;, e) continue &#125; log.Printf(&quot;Processing event %+v&quot;, e) eventUUID, ret := e.Device.GetUUID() if ret != nvml.SUCCESS &#123; // If we cannot reliably determine the device UUID, we mark all devices as unhealthy. log.Printf(&quot;Failed to determine uuid for event %v: %v; Marking all devices as unhealthy.&quot;, e, ret) for _, d := range devices &#123; unhealthy &lt;- d &#125; continue &#125; d, exists := parentToDeviceMap[eventUUID] if !exists &#123; log.Printf(&quot;Ignoring event for unexpected device: %v&quot;, eventUUID) continue &#125; if d.IsMigDevice() &amp;&amp; e.GpuInstanceId != 0xFFFFFFFF &amp;&amp; e.ComputeInstanceId != 0xFFFFFFFF &#123; gi := deviceIDToGiMap[d.ID] ci := deviceIDToCiMap[d.ID] if !(uint32(gi) == e.GpuInstanceId &amp;&amp; uint32(ci) == e.ComputeInstanceId) &#123; continue &#125; log.Printf(&quot;Event for mig device %v (gi=%v, ci=%v)&quot;, d.ID, gi, ci) &#125; log.Printf(&quot;XidCriticalError: Xid=%d on Device=%s; marking device as unhealthy.&quot;, e.EventData, d.ID) unhealthy &lt;- d &#125;&#125; checkhealth的主要原理图如下： 需要特别说明healthcheck部分： healthcheck启动协程对管理的devices进行健康状态监控，一旦发现有device unhealthy，则发送到NvidiaDevicePlugin的health channel。device plugin的ListAndWatch会从health channel中获取这些unhealthy devices，并通知到kubelet进行更新。 只监控EventTypeXidCriticalError事件，一旦监控到某个device的这个Event，就认为该device unhealthy。关于EventTypeXidCriticalError的说明，请参考NVIDIA的nvml api文档。 可以通过设置NVIDIA device plugin Pod内的环境变量DP_DISABLE_HEALTHCHECKS为”all”来取消healthcheck。不设置或者设置为其他值都会启动healthcheck，默认部署时不设置。 stopPluginsk8s-device-plugin/cmd/nvidia-device-plugin/main.go#275 func (plugin *NvidiaDevicePlugin) Stop() error &#123; if plugin == nil || plugin.server == nil &#123; return nil &#125; log.Printf(&quot;Stopping to serve &#x27;%s&#x27; on %s&quot;, plugin.rm.Resource(), plugin.socket) plugin.server.Stop() if err := os.Remove(plugin.socket); err != nil &amp;&amp; !os.IsNotExist(err) &#123; return err &#125; plugin.cleanup() return nil&#125; stopPlugins主要做三件事： 停止 device-plugin 的 grpc server 移除 plugin socket 文件 （/var/lib/kubelet/device-plugins/nvidia-gpu.sock） 清空 nvidiaDevicePlugin 相关字段。（plugin.server=nil; plugin.health=nil; plugin.stop=nil） ListAndWatchk8s-device-plugin/cmd/nvidia-device-plugin/server.go#219 func (plugin *NvidiaDevicePlugin) ListAndWatch(e *pluginapi.Empty, s pluginapi.DevicePlugin_ListAndWatchServer) error &#123; s.Send(&amp;pluginapi.ListAndWatchResponse&#123;Devices: plugin.apiDevices()&#125;) for &#123; select &#123; case &lt;-plugin.stop: return nil case d := &lt;-plugin.health: // FIXME: there is no way to recover from the Unhealthy state. d.Health = pluginapi.Unhealthy log.Printf(&quot;&#x27;%s&#x27; device marked unhealthy: %s&quot;, plugin.rm.Resource(), d.ID) s.Send(&amp;pluginapi.ListAndWatchResponse&#123;Devices: plugin.apiDevices()&#125;) &#125; &#125;&#125; listAndWatch 的实现流程图如下： Allocatek8s-device-plugin/cmd/nvidia-device-plugin/server.go#254 allocateRequest的请求结构体如下： type AllocateRequest struct &#123; ContainerRequests []*ContainerAllocateRequest&#125;type ContainerAllocateRequest struct &#123; DevicesIDs []string &#125; allocateResponse的结构体如下： type AllocateResponse struct &#123; ContainerResponses []*ContainerAllocateResponse&#125;type ContainerAllocateResponse struct &#123; Envs map[string]string Mounts []*Mount Devices []*DeviceSpec Annotations map[string]string&#125; Allocate 在容器创建期间调用，这样设备插件可以运行一些特定于设备的操作，并告诉 kubelet 如何令 Device 可在容器中访问的所需执行的具体步骤。 func (plugin *NvidiaDevicePlugin) Allocate(ctx context.Context, reqs *pluginapi.AllocateRequest) (*pluginapi.AllocateResponse, error) &#123; responses := pluginapi.AllocateResponse&#123;&#125; for _, req := range reqs.ContainerRequests &#123; // If the devices being allocated are replicas, then (conditionally) // error out if more than one resource is being allocated. if plugin.config.Sharing.TimeSlicing.FailRequestsGreaterThanOne &amp;&amp; rm.AnnotatedIDs(req.DevicesIDs).AnyHasAnnotations() &#123; if len(req.DevicesIDs) &gt; 1 &#123; return nil, fmt.Errorf(&quot;request for &#x27;%v: %v&#x27; too large: maximum request size for shared resources is 1&quot;, plugin.rm.Resource(), len(req.DevicesIDs)) &#125; &#125; for _, id := range req.DevicesIDs &#123; if !plugin.rm.Devices().Contains(id) &#123; return nil, fmt.Errorf(&quot;invalid allocation request for &#x27;%s&#x27;: unknown device: %s&quot;, plugin.rm.Resource(), id) &#125; &#125; response := pluginapi.ContainerAllocateResponse&#123;&#125; ids := req.DevicesIDs deviceIDs := plugin.deviceIDsFromAnnotatedDeviceIDs(ids) if *plugin.config.Flags.Plugin.DeviceListStrategy == spec.DeviceListStrategyEnvvar &#123; response.Envs = plugin.apiEnvs(plugin.deviceListEnvvar, deviceIDs) &#125; if *plugin.config.Flags.Plugin.DeviceListStrategy == spec.DeviceListStrategyVolumeMounts &#123; response.Envs = plugin.apiEnvs(plugin.deviceListEnvvar, []string&#123;deviceListAsVolumeMountsContainerPathRoot&#125;) response.Mounts = plugin.apiMounts(deviceIDs) &#125; if *plugin.config.Flags.Plugin.PassDeviceSpecs &#123; response.Devices = plugin.apiDeviceSpecs(*plugin.config.Flags.NvidiaDriverRoot, ids) &#125; if *plugin.config.Flags.GDSEnabled &#123; response.Envs[&quot;NVIDIA_GDS&quot;] = &quot;enabled&quot; &#125; if *plugin.config.Flags.MOFEDEnabled &#123; response.Envs[&quot;NVIDIA_MOFED&quot;] = &quot;enabled&quot; &#125; responses.ContainerResponses = append(responses.ContainerResponses, &amp;response) &#125; return &amp;responses, nil&#125; Allocate中会遍历ContainerRequests，将DeviceIDs封装到ContainerAllocateResponse的Envs:NVIDIA_VISIBLE_DEVICES中，格式为：”$&#123;ID_1&#125;,$&#123;ID_2&#125;,...” 除此之外，并没有封装Mounts, Devices, Annotations。 总结NVIDIA/k8s-device-plugin的代码中，依赖于nvidia-docker代码库，存在很多golang调用C库的地方，还需要大家自行到 nvml api文档 中查看相关C函数声明。这篇博客介绍NVIDIA/k8s-device-plugin的代码实现流程，下一篇博客我觉得还有必要对kubelet device plugin manger进行代码分析，如此才能完整的理解整个交互细节。","categories":[{"name":"device-plugins","slug":"device-plugins","permalink":"http://lizhewei91.github.io/categories/device-plugins/"}],"tags":[{"name":"device-plugins","slug":"device-plugins","permalink":"http://lizhewei91.github.io/tags/device-plugins/"},{"name":"nvidia","slug":"nvidia","permalink":"http://lizhewei91.github.io/tags/nvidia/"},{"name":"gpu","slug":"gpu","permalink":"http://lizhewei91.github.io/tags/gpu/"}]},{"title":"kubelet源码分析","slug":"kubelet-one","date":"2022-12-09T04:00:44.000Z","updated":"2022-12-09T07:53:27.812Z","comments":true,"path":"2022/12/09/44/","link":"","permalink":"http://lizhewei91.github.io/2022/12/09/44/","excerpt":"","text":"kubelet 主要功能在kubernetes集群中，每个Node节点都会启动kubelet进程，用来处理Master节点下发到本节点的任务，管理Pod和其中的容器。 pod管理Kubelet 以 PodSpec 的方式工作。PodSpec 是描述一个 Pod 的 YAML 或 JSON 对象。 kubelet 采用一组通过各种机制提供的 PodSpecs（主要通过 apiserver），并确保这些 PodSpecs 中描述的 Pod 正常健康运行。 官方提供了3种方式来获取容器信息： apiserver：通过 API Server 监听 etcd 目录获取数据； File：启动参数 –config 指定的配置目录下的文件； 通过 url 从网络上某个地址来获取信息 拿apiserver来说，如果Kubelet 监听到etcd中有新的绑定到本节点的 Pod，则按照 Pod 清单的要求创建该 Pod；如果发现本地的 Pod 被修改，则 Kubelet 会做出相应的修改。","categories":[{"name":"kubelet","slug":"kubelet","permalink":"http://lizhewei91.github.io/categories/kubelet/"}],"tags":[{"name":"kubelet","slug":"kubelet","permalink":"http://lizhewei91.github.io/tags/kubelet/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://lizhewei91.github.io/tags/kubernetes/"},{"name":"源码分析","slug":"源码分析","permalink":"http://lizhewei91.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"}]},{"title":"浅谈k8s中device-plugins机制","slug":"device-plugins","date":"2022-11-29T02:53:16.000Z","updated":"2023-01-06T07:31:40.008Z","comments":true,"path":"2022/11/29/16/","link":"","permalink":"http://lizhewei91.github.io/2022/11/29/16/","excerpt":"","text":"Extended Resource官方链接：extended-resource-node 特性状态： Kubernetes v1.9 [stable] 可以用一句话来概括这个特性：通过向apiserver发送一个 patch node 的请求，为这个node增加一个自定义的资源类型，用于以该资源的配额统计和相应的QoS的配置。 为节点增加扩展资源为在一个节点上发布一种新的扩展资源，需要发送一个 HTTP PATCH 请求到 Kubernetes API server。 例如：假设你的一个节点上带有四个 dongle 资源。 下面是一个 PATCH 请求的示例，该请求为你的节点发布四个 dongle 资源。 PATCH /api/v1/nodes/&lt;your-node-name&gt;/status HTTP/1.1Accept: application/jsonContent-Type: application/json-patch+jsonHost: k8s-master:8080[ &#123; &quot;op&quot;: &quot;add&quot;, &quot;path&quot;: &quot;/status/capacity/example.com~1dongle&quot;, &quot;value&quot;: &quot;4&quot; &#125;] 注意：Kubernetes 不需要了解 dongle 资源的含义和用途。 前面的 PATCH 请求告诉 Kubernetes 你的节点拥有四个你称之为 dongle 的东西。 启动一个代理（proxy），以便你可以很容易地向 Kubernetes API server 发送请求： kubectl proxy 在另一个命令窗口中，发送 HTTP PATCH 请求。 用你的节点名称替换 &lt;your-node-name&gt;： curl --header &quot;Content-Type: application/json-patch+json&quot; \\ --request PATCH \\ --data &#x27;[&#123;&quot;op&quot;: &quot;add&quot;, &quot;path&quot;: &quot;/status/capacity/example.com~1dongle&quot;, &quot;value&quot;: &quot;4&quot;&#125;]&#x27; \\ http://localhost:8001/api/v1/nodes/&lt;your-node-name&gt;/status 说明： 在前面的请求中，~1 为 patch 路径中 “/” 符号的编码。 JSON-Patch 中的操作路径值被解析为 JSON 指针。 kubectl describe node &lt;your-node-name&gt; 清理扩展资源这里是一个从节点移除 dongle 资源发布的 PATCH 请求。 PATCH /api/v1/nodes/&lt;your-node-name&gt;/status HTTP/1.1Accept: application/jsonContent-Type: application/json-patch+jsonHost: k8s-master:8080[ &#123; &quot;op&quot;: &quot;remove&quot;, &quot;path&quot;: &quot;/status/capacity/example.com~1dongle&quot;, &#125;] 启动一个代理，以便你可以很容易地向 Kubernetes API 服务器发送请求： kubectl proxy 在另一个命令窗口中，发送 HTTP PATCH 请求。用你的节点名称替换 &lt;your-node-name&gt;： curl --header &quot;Content-Type: application/json-patch+json&quot; \\--request PATCH \\--data &#x27;[&#123;&quot;op&quot;: &quot;remove&quot;, &quot;path&quot;: &quot;/status/capacity/example.com~1dongle&quot;&#125;]&#x27; \\http://localhost:8001/api/v1/nodes/&lt;your-node-name&gt;/status 验证 dongle 资源的发布已经被移除： kubectl describe node &lt;your-node-name&gt; | grep dongle (你应该看不到任何输出) 扩展资源是 kubernetes.io 域名之外的标准资源名称。 它们使得集群管理员能够颁布非 Kubernetes 内置资源，而用户可以使用他们。 使用扩展资源需要两个步骤。首先，集群管理员必须颁布扩展资源。 其次，用户必须在 Pod 中请求扩展资源。 Device Plugins官方链接：device-plugins 特性状态： Kubernetes v1.26 [stable] Kubernetes 提供了一个 设备插件框架， 你可以用它来将系统硬件资源发布到 Kubelet。 供应商可以实现设备插件，由你手动部署或作为 DaemonSet 来部署，而不必定制 Kubernetes 本身的代码。目标设备包括 GPU、高性能 NIC、FPGA、 InfiniBand 适配器以及其他类似的、可能需要特定于供应商的初始化和设置的计算资源。 设备插件框架 设备插件的常规工作流程包括以下几个步骤： 初始化。在这个阶段，设备插件将执行供应商特定的初始化和设置， 以确保设备处于就绪状态。 插件使用主机路径 /var/lib/kubelet/device-plugins/ 下的 Unix 套接字启动一个 gRPC 服务，如：/var/lib/kubelet/device-plugins/nvidia-gpu.sock，该服务实现以下接口： service DevicePlugin &#123; // GetDevicePluginOptions 返回与设备管理器沟通的选项。 rpc GetDevicePluginOptions(Empty) returns (DevicePluginOptions) &#123;&#125; // ListAndWatch 返回 Device 列表构成的数据流。 // 当 Device 状态发生变化或者 Device 消失时，ListAndWatch // 会返回新的列表。 rpc ListAndWatch(Empty) returns (stream ListAndWatchResponse) &#123;&#125; // Allocate 在容器创建期间调用，这样设备插件可以运行一些特定于设备的操作， // 并告诉 kubelet 如何令 Device 可在容器中访问的所需执行的具体步骤 rpc Allocate(AllocateRequest) returns (AllocateResponse) &#123;&#125; // GetPreferredAllocation 从一组可用的设备中返回一些优选的设备用来分配， // 所返回的优选分配结果不一定会是设备管理器的最终分配方案。 // 此接口的设计仅是为了让设备管理器能够在可能的情况下做出更有意义的决定。 rpc GetPreferredAllocation(PreferredAllocationRequest) returns (PreferredAllocationResponse) &#123;&#125; // PreStartContainer 在设备插件注册阶段根据需要被调用，调用发生在容器启动之前。 // 在将设备提供给容器使用之前，设备插件可以运行一些诸如重置设备之类的特定于 // 具体设备的操作， rpc PreStartContainer(PreStartContainerRequest) returns (PreStartContainerResponse) &#123;&#125;&#125; 插件通过 Unix socket 在主机路径 /var/lib/kubelet/device-plugins/kubelet.sock 处向 kubelet 注册自身。 成功注册自身后，设备插件将以服务模式运行，在此期间，它将持续监控设备运行状况， 并在设备状态发生任何变化时向 kubelet 报告。它还负责响应 Allocate gRPC 请求。 在 Allocate 期间，设备插件可能还会做一些设备特定的准备；例如 GPU 清理或 QRNG 初始化。 如果操作成功，则设备插件将返回 AllocateResponse，其中包含用于访问被分配的设备容器运行时的配置。 kubelet 将此信息传递到容器运行时。 处理 kubelet 重启 设备插件应能监测到 kubelet 重启，并且向新的 kubelet 实例来重新注册自己。 新的 kubelet 实例启动时会删除 /var/lib/kubelet/device-plugins 下所有已经存在的 Unix 套接字。 设备插件需要能够监控到它的 Unix 套接字被删除，并且当发生此类事件时重新注册自己。","categories":[{"name":"device-plugins","slug":"device-plugins","permalink":"http://lizhewei91.github.io/categories/device-plugins/"}],"tags":[{"name":"kubernetnes","slug":"kubernetnes","permalink":"http://lizhewei91.github.io/tags/kubernetnes/"},{"name":"device-plugins","slug":"device-plugins","permalink":"http://lizhewei91.github.io/tags/device-plugins/"}]},{"title":"hexo+typora图片插入","slug":"hexo-typora-photos","date":"2022-11-28T14:46:29.000Z","updated":"2022-11-28T14:52:49.556Z","comments":true,"path":"2022/11/28/29/","link":"","permalink":"http://lizhewei91.github.io/2022/11/28/29/","excerpt":"","text":"Typora设置。点击文件-&gt;偏好设置-&gt;图像，配置插入图片问复制到指定路径，底下三个勾都选，如下图所示。 Hexo配置。在根目录下，进入bash命令框，输入npm install hexo-image-link --save安装插件。 更改根目录下_config.yml配置，找到post_asset_folder，改为true。 写文章前，在根目录bash命令框中输入hexo new 文章题目，可以自动在post文件夹中生成文章题目.md与文章题目图片存储目录了。 这样就配置成功了。写文章之前，现在你可以把图片像word编辑一样拖动到typora直接预览，该过程不需要输入什么图片插入指令呀存储路径呀啥的，也不需要专门去对图片进行转存；直接网页端预览，图片可以正常显示。","categories":[{"name":"hexo","slug":"hexo","permalink":"http://lizhewei91.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://lizhewei91.github.io/tags/hexo/"}]},{"title":"性能剖析大杀器 pprof","slug":"golang-pprof","date":"2022-11-28T12:28:56.000Z","updated":"2022-12-01T07:36:27.356Z","comments":true,"path":"2022/11/28/56/","link":"","permalink":"http://lizhewei91.github.io/2022/11/28/56/","excerpt":"","text":"pprof在 Go 语言中，PProf 是用于可视化和分析性能分析数据的工具，pprof 以 profile.proto 读取分析样本的集合，并生成报告以可视化并帮助分析数据（支持文本和图形报告）。 而刚刚提到的 profile.proto 是一个 Protobuf v3 的描述文件，它描述了一组 callstack 和 symbolization 信息， 作用是统计分析的一组采样的调用栈，是很常见的 stacktrace 配置文件格式。 可以做什么 CPU Profiling：CPU 分析，按照一定的频率采集所监听的应用程序 CPU（含寄存器）的使用情况，可确定应用程序在主动消耗 CPU 周期时花费时间的位置。 Memory Profiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 Block Profiling：阻塞分析，记录Goroutine阻塞等待同步（包括定时器通道）的位置，默认不开启，需要调用 runtime.SetBlockProfileRate进行设置。 Mutex Profiling：互斥锁分析，报告互斥锁的竞争情况，默认不开启，需要调用 runtime.SetMutexProfileFraction 进行设置。 Goroutine Profiling：Goroutine 分析，可以对当前应用程序正在运行的 Goroutine 进行堆栈跟踪和分析。 其中像是 Goroutine Profiling 这项功能会在实际排查中会经常用到。因为很多问题出现时的表象就是 Goroutine 暴增，而这时候我们要做的事情之一就是查看应用程序中的 Goroutine 正在做什么事情，因为什么阻塞了，然后再进行下一步。 采样方式 runtime/pprof：采集程序（非 Server）的指定区块的运行数据进行分析。 net/http/pprof：基于HTTP Server运行，并且可以采集运行时数据进行分析。 go test：通过运行测试用例，并指定所需标识来进行采集。 使用模式 Report generation：报告生成。 Interactive terminal use：交互式终端使用。 Web interface：Web 界面。 服务型应用如果你的应用程序是一直运行的，比如 web 应用，那么可以使用net/http/pprof库，它能够在提供 HTTP 服务进行分析。 如果使用了默认的 http.DefaultServeMux（通常是代码直接使用 http.ListenAndServe(“0.0.0.0:8080”, nil)），只需要在你的web server端代码中按如下方式导入net/http/pprof import _ &quot;net/http/pprof&quot; 为什么要初始化net/http/pprof在我们的例子中，你会发现我们在引用上对 net/http/pprof包进行了默认的初始化（也就是 _），如果你曾经漏了，或者没加，你会发现压根调用不了 pprof 的相关接口，这是为什么呢，我们一起看看下面该包的初始化方法，如下： func init() &#123; http.HandleFunc(&quot;/debug/pprof/&quot;, Index) http.HandleFunc(&quot;/debug/pprof/cmdline&quot;, Cmdline) http.HandleFunc(&quot;/debug/pprof/profile&quot;, Profile) http.HandleFunc(&quot;/debug/pprof/symbol&quot;, Symbol) http.HandleFunc(&quot;/debug/pprof/trace&quot;, Trace)&#125; 实际上 net/http/pprof会在初始化函数中对标准库中net/http所默认提供的 DefaultServeMux 进行路由注册，源码如下： var DefaultServeMux = &amp;defaultServeMuxvar defaultServeMux ServeMuxfunc HandleFunc(pattern string, handler func(ResponseWriter, *Request)) &#123; DefaultServeMux.HandleFunc(pattern, handler)&#125; 而我们在例子中使用的 HTTP Server，也是使用的标准库中默认提供的，因此便完美的结合在了一起，这也恰好也是最小示例的模式。 这时候你可能会注意到另外一个问题，那就是我们的实际项目中，都是有相对独立的 ServeMux 的，这时候我们只要仿照着将 pprof 对应的路由注册进去就好了，如下： mux := http.NewServeMux()mux.HandleFunc(&quot;/debug/pprof/&quot;, pprof.Index)mux.HandleFunc(&quot;/debug/pprof/cmdline&quot;, pprof.Cmdline)mux.HandleFunc(&quot;/debug/pprof/profile&quot;, pprof.Profile)mux.HandleFunc(&quot;/debug/pprof/symbol&quot;, pprof.Symbol)mux.HandleFunc(&quot;/debug/pprof/trace&quot;, pprof.Trace) 如果你使用的是gin框架，那么推荐使用 github.com/gin-contrib/pprof，在代码中通过以下命令注册 pprof 相关路由。 pprof.Register(router) 一个简单的例子package mainimport ( &quot;log&quot; &quot;net/http&quot; _ &quot;net/http/pprof&quot; &quot;time&quot;)var datas []stringfunc main() &#123; str := &quot;hello,world&quot; go func() &#123; for &#123; log.Printf(&quot;len:%d\\n&quot;, Add(str)) time.Sleep(10 * time.Millisecond) &#125; &#125;() _ = http.ListenAndServe(&quot;0.0.0.0:8080&quot;, nil)&#125;func Add(str string) int &#123; datas = append(datas, str) return len(datas)&#125; 接下来我们运行这个程序，访问 http://127.0.0.1:8080/debug/pprof/ 地址，检查是否正常响应。 通过浏览器访问第一种方式，我们可以直接通过浏览器，进行查看，那么在第一步我们可以先查看总览页面，也就是访问 http://127.0.0.1:8080/debug/pprof/，如下： /debug/pprof/Types of profiles available:Count Profile3 allocs0 block0 cmdline5 goroutine3 heap0 mutex0 profile8 threadcreate0 tracefull goroutine stack dump allocs：查看过去所有内存分配的样本，访问路径为$HOST/debug/pprof/allocs。 block：查看导致阻塞同步的堆栈跟踪，访问路径为$HOST/debug/pprof/block。 cmdline：当前程序的命令行的完整调用路径，访问路径为$HOST/debug/pprof/cmdline。 goroutine：查看当前所有运行的 goroutines 堆栈跟踪，访问路径为$HOST/debug/pprof/goroutine。 heap：查看活动对象的内存分配情况， 访问路径为$HOST/debug/pprof/heap。 mutex：查看导致互斥锁的竞争持有者的堆栈跟踪，访问路径为$HOST/debug/pprof/mutex。 profile：默认进行 30s 的 CPU Profiling，得到一个分析用的 profile 文件，访问路径为$HOST/debug/pprof/profile。 threadcreate：查看创建新OS线程的堆栈跟踪，访问路径为$HOST/debug/pprof/threadcreate。 如果在相应的路径上加“?debug=1”，则可以直接在浏览器中访问，如图所示： 若不新增debug参数，则会直接下载对应的profile文件。 注意：debug的访问方式具有时效性，在实际场景中，我们通常将profile文件保存下来，便于二次分析。 通过交互式终端使用CPU Profiling第二种方式，我们可以直接通过命令行，来完成对正在运行的应用程序 pprof 的抓取和分析。 $ go tool pprof http://localhost:8080/debug/pprof/profile?seconds=60Fetching profile over HTTP from http://localhost:6060/debug/pprof/profile?seconds=60Saved profile in /Users/eddycjy/pprof/pprof.samples.cpu.002.pb.gzType: cpuDuration: 1mins, Total samples = 37.25s (61.97%)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) 执行该命令后，需等待 60 秒（可调整 seconds 的值），pprof 会进行 CPU Profiling，结束后将默认进入 pprof 的命令行交互式模式，可以对分析的结果进行查看或导出。另外如果你所启动的 HTTP Server 是 TLS 的方式，那么在调用go tool pprof 时，需要将调用路径改为：go tool pprof https+insecure://localhost:8080/debug/pprof/profile\\?seconds\\=60。 (pprof) top10Showing nodes accounting for 1.38s, 100% of 1.38s totalShowing top 10 nodes out of 50 flat flat% sum% cum cum% 0.60s 43.48% 43.48% 0.80s 57.97% runtime.kevent 0.31s 22.46% 65.94% 0.31s 22.46% runtime.libcCall 0.21s 15.22% 81.16% 0.22s 15.94% syscall.syscall 0.15s 10.87% 92.03% 0.26s 18.84% runtime.pthread_cond_wait 0.04s 2.90% 94.93% 0.04s 2.90% runtime.pthread_cond_signal 0.02s 1.45% 96.38% 0.02s 1.45% runtime.walltime 0.02s 1.45% 97.83% 0.02s 1.45% runtime.write1 0.01s 0.72% 98.55% 0.01s 0.72% log.itoa 0.01s 0.72% 99.28% 0.01s 0.72% runtime.(*mcache).prepareForSweep 0.01s 0.72% 100% 0.01s 0.72% runtime.memmove flat：函数自身的运行耗时。 flat%：函数自身在 CPU 运行耗时总比例。 sum%：函数自身累积使用 CPU 总比例。 cum：函数自身及其调用函数的运行总耗时。 cum%：函数自身及其调用函数的运行耗时总比例。 Name：函数名。 在大多数的情况下，我们可以通过这五列得出一个应用程序的运行情况，知道当前是什么函数，正在做什么事情，占用了多少资源，谁又是占用资源的大头，以此来得到一个初步的分析方向。 另外在交互命令行中，pprof 还支持了大量的其它命令，具体可执行 pprof help 查看帮助说明。 Heap Profiling$ go tool pprof http://localhost:8080/debug/pprof/heapFetching profile over HTTP from http://localhost:8080/debug/pprof/heapSaved profile in /Users/lizhewei/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.001.pb.gzType: inuse_spaceTime: Dec 15, 2021 at 4:56pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) 执行该命令后，能够很快的拉取到其结果，因为它不需要像 CPU Profiling 做采样等待，这里需要注意的一点是 Type 这一个选项，你可以看到它默认显示的是 inuse_space，实际上可以针对多种内存概况进行分析，常用的类别如下： 一共有四种类型： inuse_space：分析应用程序的常驻内存占用情况。 alloc_objects：分析应用程序的内存临时分配情况。 inuse_objects：查看每个函数所分别的对象数量。 alloc_space：查看分配的内存空间大小。 inuse_space：分析应用程序的常驻内存占用情况。 $ go tool pprof -inuse_space http://localhost:8080/debug/pprof/heapFetching profile over HTTP from http://localhost:8080/debug/pprof/heapSaved profile in /Users/lizhewei/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.002.pb.gzType: inuse_spaceTime: Dec 15, 2021 at 4:59pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) topShowing nodes accounting for 4130.49kB, 100% of 4130.49kB totalShowing top 10 nodes out of 20 flat flat% sum% cum cum% 1567.04kB 37.94% 37.94% 1567.04kB 37.94% main.Add (inline) 1537.69kB 37.23% 75.17% 1537.69kB 37.23% runtime.allocm 513.56kB 12.43% 87.60% 513.56kB 12.43% regexp/syntax.init 512.20kB 12.40% 100% 512.20kB 12.40% runtime.malg 0 0% 100% 1567.04kB 37.94% main.main.func1 alloc_objects：分析应用程序的内存临时分配情况。 $ go tool pprof -alloc_objects http://localhost:8080/debug/pprof/heapFetching profile over HTTP from http://localhost:8080/debug/pprof/heapSaved profile in /Users/lizhewei/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.003.pb.gzType: alloc_objectsTime: Dec 15, 2021 at 5:01pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) topShowing nodes accounting for 311313, 99.07% of 314251 totalDropped 39 nodes (cum &lt;= 1571) flat flat% sum% cum cum% 163842 52.14% 52.14% 311313 99.07% main.main.func1 131074 41.71% 93.85% 131074 41.71% fmt.Sprintf 16397 5.22% 99.07% 16397 5.22% main.Add (inline) 0 0% 99.07% 131074 41.71% log.Printf 另外还有 inuse_objects 和 alloc_space 类别，分别对应查看每个函数所分别的对象数量和查看分配的内存空间大小，具体可根据情况选用。 Goroutine Profiling$ go tool pprof http://localhost:8080/debug/pprof/goroutineFetching profile over HTTP from http://localhost:8080/debug/pprof/goroutineSaved profile in /Users/lizhewei/pprof/pprof.goroutine.001.pb.gzType: goroutineTime: Dec 15, 2021 at 5:04pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) 在查看 goroutine 时，我们可以使用 traces 命令，这个命令会打印出对应的所有调用栈，以及指标信息，可以让我们很便捷的查看到整个调用链路有什么，分别在哪里使用了多少个 goroutine，并且能够通过分析查看到谁才是真正的调用方，输出结果如下： (pprof) tracesType: goroutine-----------+------------------------------------------------------- 2 runtime.gopark runtime.netpollblock internal/poll.runtime_pollWait ...-----------+------------------------------------------------------- 1 runtime.gopark runtime.netpollblock ... net/http.ListenAndServe main.main runtime.main 在调用栈上来讲，其展示顺序是自下而上的，也就是 runtime.main 方法调用了 main.main 方法，main.main 方法又调用了 net/http.ListenAndServe 方法，这里对应的也就是我们所使用的示例代码了，排查起来会非常方便。 每个调用堆栈信息用 ----------- 分割，函数方法前的就是指标数据，像 Goroutine Profiling 展示是就是该方法占用的 goroutine 的数量。而 Heap Profiling 展示的就是占用的内存大小，如下： $ go tool pprof http://localhost:8080/debug/pprof/heap...Type: inuse_spaceEntering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) tracesType: inuse_space-----------+------------------------------------------------------- bytes: 13.55MB 13.55MB main.Add main.main.func1-----------+------------------------------------------------------- Mutex Profiling怎么样的情况下会造成阻塞呢，一般有如下方式：调用 chan（通道）、调用 sync.Mutex （同步锁）、调用 time.Sleep() 等等。那么为了验证互斥锁的竞争持有者的堆栈跟踪，我们可以根据以上的 sync.Mutex 方式，来调整先前的示例代码，代码如下： func init() &#123; runtime.SetMutexProfileFraction(1)&#125;func main() &#123; var m sync.Mutex var datas = make(map[int]struct&#123;&#125;) for i := 0; i &lt; 999; i++ &#123; go func(i int) &#123; m.Lock() defer m.Unlock() datas[i] = struct&#123;&#125;&#123;&#125; &#125;(i) &#125; _ = http.ListenAndServe(&quot;:6061&quot;, nil)&#125; 需要特别注意的是 runtime.SetMutexProfileFraction 语句，如果未来希望进行互斥锁的采集，那么需要通过调用该方法来设置采集频率，若不设置或没有设置大于 0 的数值，默认是不进行采集的。 接下来我们进行调用 go tool pprof 进行分析，如下： $ go tool pprof http://localhost:8081/debug/pprof/mutexFetching profile over HTTP from http://localhost:8081/debug/pprof/mutexSaved profile in /Users/lizhewei/pprof/pprof.contentions.delay.002.pb.gzType: delayTime: Dec 15, 2021 at 5:18pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) 我们查看调用 top 命令，查看互斥量的排名： (pprof) topShowing nodes accounting for 1.77ms, 100% of 1.77ms total flat flat% sum% cum cum% 1.77ms 100% 100% 1.77ms 100% sync.(*Mutex).Unlock 0 0% 100% 1.77ms 100% main.main.func1 接下来我们可以调用 list 命令，看到指定函数的代码情况（包含特定的指标信息，例如：耗时），若函数名不明确，默认会对函数名进行模糊匹配，如下： (pprof) list mainTotal: 1.77msROUTINE ======================== main.main.func1 in /Volumes/D/go/src/github.com/lizw91/pprof/main.go 0 1.77ms (flat, cum) 100% of Total . . 17: for i := 0; i &lt; 1000; i++ &#123; . . 18: go func(i int) &#123; . . 19: m.Lock() . . 20: defer m.Unlock() . . 21: datas[i] = struct&#123;&#125;&#123;&#125; . 1.77ms 22: &#125;(i) . . 23: &#125; . . 24: . . 25: _ = http.ListenAndServe(&quot;:8081&quot;, nil) . . 26:&#125; 我们可以在输出的分析中比较准确的看到引起互斥锁的函数在哪里，锁开销在哪里，在本例中是第 22 行。 Block Profiling与 Mutex 的 runtime.SetMutexProfileFraction 相似，Block 也需要调用 runtime.SetBlockProfileRate() 进行采集量的设置，否则默认关闭，若设置的值小于等于 0 也会认为是关闭。 与上小节 Mutex 相比，主体代码不变，仅是新增 runtime.SetBlockProfileRate()的调用，如下： 示例代码 package mainimport ( &quot;net/http&quot; _ &quot;net/http/pprof&quot; &quot;runtime&quot; &quot;sync&quot;)func init() &#123; runtime.SetBlockProfileRate(1)&#125;func main() &#123; var m sync.Mutex var datas = make(map[int]struct&#123;&#125;) for i := 0; i &lt; 1000; i++ &#123; go func(i int) &#123; m.Lock() defer m.Unlock() datas[i] = struct&#123;&#125;&#123;&#125; &#125;(i) &#125; _ = http.ListenAndServe(&quot;:8081&quot;, nil)&#125; 我们查看调用 top 命令，查看阻塞情况的排名： $ go tool pprof http://localhost:8081/debug/pprof/blockFetching profile over HTTP from http://localhost:8081/debug/pprof/blockSaved profile in /Users/lizhewei/pprof/pprof.contentions.delay.003.pb.gzType: delayTime: Dec 15, 2021 at 5:21pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) topShowing nodes accounting for 48.97ms, 100% of 48.97ms total flat flat% sum% cum cum% 48.97ms 100% 100% 48.97ms 100% sync.(*Mutex).Lock (inline) 0 0% 100% 48.97ms 100% main.main.func1 同样的，我们也可以调用 list 命令查看具体的阻塞情况，执行方式和排查模式与先前概述的一致。 (pprof) list mainTotal: 48.97msROUTINE ======================== main.main.func1 in /Volumes/D/go/src/github.com/lizw91/pprof/main.go 0 48.97ms (flat, cum) 100% of Total . . 14:func main() &#123; . . 15: var m sync.Mutex . . 16: var datas = make(map[int]struct&#123;&#125;) . . 17: for i := 0; i &lt; 1000; i++ &#123; . . 18: go func(i int) &#123; . 48.97ms 19: m.Lock() . . 20: defer m.Unlock() . . 21: datas[i] = struct&#123;&#125;&#123;&#125; . . 22: &#125;(i) . . 23: &#125; . . 24: 查看可视化界面接下来我们继续使用前面的示例程序，将其重新运行起来，然后在其它窗口执行下述命令： // 获取 cpu 指标$ wget -O cpu.profile http://127.0.0.1:8080/debug/pprof/profile?seconds=30// 获取 heap 指标 $ wget -O mem.profile http://127.0.0.1:8080/debug/pprof/profile?seconds=30 默认需要等待 30 秒，执行完毕后可在当前目录下发现采集的文件 cpu.profile，针对可视化界面我们有两种方式可进行下一步分析： 方法一（推荐）：该命令将在所指定的端口号运行一个 pprof 的分析用的站点 $ go tool pprof -http=:8081 cpu.profile 方法二：通过 web 命令将以 svg 的文件格式写入图形，然后在 Web 浏览器中将其打开。 $ go tool pprof cpu.profileType: cpuTime: Feb 1, 2020 at 12:09pm (CST)Duration: 30s, Total samples = 60ms ( 0.2%)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) web 如果出现错误提示 Could not execute dot; may need to install graphviz.，那么意味着你需要安装 graphviz组件。 另外方法一所运行的站点，实际上包含了方法二的内容（svg图片），并且更灵活，因此非特殊情况，我们会直接使用方法一的方式运行站点来做观察和分析。 通过 pprof 所提供的可视化界面，我们能够更方便、更直观的看到 Go 应用程序的调用链、使用情况等。 另外在 View 菜单栏中，PProf 还支持多种分析方式的切换，如下： view 菜单栏 接下来我们将基于 CPU Profiling 所抓取的 Profile 进行一一介绍，而其它 Profile 类型的分析模式也是互通的，只要我们了解了一种，其余的也就会了。 Top flat：函数自身的运行耗时。 flat%：函数自身在 CPU 运行耗时总比例。 sum%：函数自身累积使用 CPU 总比例。 cum：函数自身及其调用函数的运行总耗时。 cum%：函数自身及其调用函数的运行耗时总比例。 Name：函数名。 Graph 该视图展示的为整体的函数调用流程，框越大、线越粗、框颜色越鲜艳（红色）就代表它占用的时间越久，开销越大。相反若框颜色越淡，越小则代表在整体的函数调用流程中，它的开销是相对较小的。因此我们可以用此视图去分析谁才是开销大头，它又是因为什么调用流程而被调用的。 Peek peek 栏目，此视图相较于 Top 视图，增加了所属的上下文信息的展示，也就是函数的输出调用者/被调用者。 Source source 栏目，该视图主要是增加了面向源代码的追踪和分析，可以看到其开销主要消耗在哪里。 flame graph Flame Graph（火焰图）它是可动态的，调用顺序由上到下（A -&gt; B -&gt; C -&gt; D），每一块代表一个函数、颜色越鲜艳（红）、区块越大代表占用 CPU 的时间更长。同时它也支持点击块深入进行分析。 我们选择页面上的 main.main.func1 区块，将会进入到其属下的下一层级，如下： 进一步查看 flame graph，这样子我们就可以根据不同函数的多维度层级进行分析，能够更好的观察其流转并发现问题。 工具型应用如果你的应用程序是运行一段时间就结束退出类型。那么最好的办法是在应用退出的时候把 profiling 的报告保存到文件中，进行分析。对于这种情况，可以使用runtime/pprof库。 首先在代码中导入runtime/pprof工具： import &quot;runtime/pprof&quot; CPU性能分析开启CPU性能分析： pprof.StartCPUProfile(w io.Writer) 停止CPU性能分析： pprof.StopCPUProfile() 应用执行结束后，就会生成一个文件，保存了我们的 CPU profiling 数据。得到采样数据之后，使用 go tool pprof工具进行 CPU 性能分析。 内存性能优化记录程序的堆栈信息 pprof.WriteHeapProfile(w io.Writer) go tool pprof默认是使用-inuse_space 进行统计，还可以使用 -inuse-objects 查看分配对象的数量。 示例// runtime_pprof/main.gopackage mainimport ( &quot;flag&quot; &quot;fmt&quot; &quot;os&quot; &quot;runtime/pprof&quot; &quot;time&quot;)// 一段有问题的代码func logicCode() &#123; var c chan int for &#123; select &#123; case v := &lt;-c: fmt.Printf(&quot;recv from chan, value:%v\\n&quot;, v) default: &#125; &#125;&#125;func main() &#123; var isCPUPprof bool var isMemPprof bool flag.BoolVar(&amp;isCPUPprof, &quot;cpu&quot;, false, &quot;turn cpu pprof on&quot;) flag.BoolVar(&amp;isMemPprof, &quot;mem&quot;, false, &quot;turn mem pprof on&quot;) flag.Parse() if isCPUPprof &#123; file, err := os.Create(&quot;./cpu.pprof&quot;) if err != nil &#123; fmt.Printf(&quot;create cpu pprof failed, err:%v\\n&quot;, err) return &#125; pprof.StartCPUProfile(file) defer pprof.StopCPUProfile() &#125; for i := 0; i &lt; 8; i++ &#123; go logicCode() &#125; time.Sleep(20 * time.Second) if isMemPprof &#123; file, err := os.Create(&quot;./mem.pprof&quot;) if err != nil &#123; fmt.Printf(&quot;create mem pprof failed, err:%v\\n&quot;, err) return &#125; pprof.WriteHeapProfile(file) file.Close() &#125;&#125; 通过flag我们可以在命令行控制是否开启 CPU和 Mem 的性能分析。 将上面的代码保存并编译成runtime_pprof 可执行文件，执行时加上 -cpu 命令行参数如下： go run main.go -cpu 等待30秒后会在当前目录下生成一个 cpu.pprof 文件。然后，执行go tool pprof命令就可以查看 $ go tool pprof cpu.pprofType: cpuTime: Dec 15, 2021 at 8:25pm (CST)Duration: 20.19s, Total samples = 119.64s (592.65%)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) topShowing nodes accounting for 119.62s, 100% of 119.64s totalDropped 2 nodes (cum &lt;= 0.60s) flat flat% sum% cum cum% 52.65s 44.01% 44.01% 52.65s 44.01% runtime.chanrecv 51.04s 42.66% 86.67% 103.69s 86.67% runtime.selectnbrecv 15.93s 13.31% 100% 119.63s 100% main.logicCode 压测工具wrk推荐使用： https://github.com/wg/wrk https://github.com/adjust/go-wrk 使用wrk进行压测: go-wrk -n 50000 http://127.0.0.1:8080/book/list 在上面压测进行的同时，打开另一个终端执行: $ go tool pprof http://localhost:8080/debug/pprof/profile?seconds=60 pprof与性能测试结合go test 命令有两个参数和 pprof 相关，它们分别指定生成的 CPU 和 Memory profiling 保存的文件： -cpuprofile：cpu profiling 数据要保存的文件地址 -memprofile：memory profiling 数据要报文的文件地址 我们还可以选择将pprof与性能测试相结合，比如： 比如下面执行测试的同时，也会执行 CPU profiling，并把结果保存在 cpu.prof 文件中： go test -bench . -cpuprofile=cpu.profile 比如下面执行测试的同时，也会执行 Mem profiling，并把结果保存在 cpu.prof 文件中： go test -bench . -memprofile=./mem.profile 注意： 获取的 Profiling 数据是动态的，要想获得有效的数据，请保证应用处于较大的负载（比如正在生成中运行的服务，或者通过其他工具模拟访问压力）。否则如果应用处于空闲状态，得到的结果可能没有任何意义。所以，Profiling 一般和性能测试一起使用","categories":[{"name":"pprof","slug":"pprof","permalink":"http://lizhewei91.github.io/categories/pprof/"}],"tags":[{"name":"pprof","slug":"pprof","permalink":"http://lizhewei91.github.io/tags/pprof/"},{"name":"性能分析","slug":"性能分析","permalink":"http://lizhewei91.github.io/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"name":"golang","slug":"golang","permalink":"http://lizhewei91.github.io/tags/golang/"}]}],"categories":[{"name":"device-plugins","slug":"device-plugins","permalink":"http://lizhewei91.github.io/categories/device-plugins/"},{"name":"kubelet","slug":"kubelet","permalink":"http://lizhewei91.github.io/categories/kubelet/"},{"name":"hexo","slug":"hexo","permalink":"http://lizhewei91.github.io/categories/hexo/"},{"name":"pprof","slug":"pprof","permalink":"http://lizhewei91.github.io/categories/pprof/"}],"tags":[{"name":"device-plugins","slug":"device-plugins","permalink":"http://lizhewei91.github.io/tags/device-plugins/"},{"name":"gpu","slug":"gpu","permalink":"http://lizhewei91.github.io/tags/gpu/"},{"name":"kubevirt-gpu-device-plugin","slug":"kubevirt-gpu-device-plugin","permalink":"http://lizhewei91.github.io/tags/kubevirt-gpu-device-plugin/"},{"name":"nvidia","slug":"nvidia","permalink":"http://lizhewei91.github.io/tags/nvidia/"},{"name":"kubelet","slug":"kubelet","permalink":"http://lizhewei91.github.io/tags/kubelet/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://lizhewei91.github.io/tags/kubernetes/"},{"name":"源码分析","slug":"源码分析","permalink":"http://lizhewei91.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"kubernetnes","slug":"kubernetnes","permalink":"http://lizhewei91.github.io/tags/kubernetnes/"},{"name":"hexo","slug":"hexo","permalink":"http://lizhewei91.github.io/tags/hexo/"},{"name":"pprof","slug":"pprof","permalink":"http://lizhewei91.github.io/tags/pprof/"},{"name":"性能分析","slug":"性能分析","permalink":"http://lizhewei91.github.io/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"name":"golang","slug":"golang","permalink":"http://lizhewei91.github.io/tags/golang/"}]}