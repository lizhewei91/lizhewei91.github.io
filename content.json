{"meta":{"title":"lizhewei'Blog","subtitle":"","description":"专注于云原生领域","author":"lizhewei","url":"http://lizhewei91.github.io","root":"/"},"pages":[{"title":"标签","date":"2022-11-25T04:12:57.000Z","updated":"2022-11-25T04:15:16.176Z","comments":true,"path":"tags/index.html","permalink":"http://lizhewei91.github.io/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-11-25T04:13:14.000Z","updated":"2022-11-25T04:15:44.664Z","comments":true,"path":"categories/index.html","permalink":"http://lizhewei91.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"浅谈k8s中device-plugins机制","slug":"device-plugins","date":"2022-11-29T02:53:16.000Z","updated":"2022-11-29T03:18:52.385Z","comments":true,"path":"2022/11/29/16/","link":"","permalink":"http://lizhewei91.github.io/2022/11/29/16/","excerpt":"","text":"Extended Resource官方链接：extended-resource-node 特性状态： Kubernetes v1.9 [stable] 可以用一句话来概括这个特性：通过向apiserver发送一个 patch node 的请求，为这个node增加一个自定义的资源类型，用于以该资源的配额统计和相应的QoS的配置。 为节点增加扩展资源为在一个节点上发布一种新的扩展资源，需要发送一个 HTTP PATCH 请求到 Kubernetes API server。 例如：假设你的一个节点上带有四个 dongle 资源。 下面是一个 PATCH 请求的示例，该请求为你的节点发布四个 dongle 资源。 PATCH /api/v1/nodes/&lt;your-node-name&gt;/status HTTP/1.1Accept: application/jsonContent-Type: application/json-patch+jsonHost: k8s-master:8080[ &#123; &quot;op&quot;: &quot;add&quot;, &quot;path&quot;: &quot;/status/capacity/example.com~1dongle&quot;, &quot;value&quot;: &quot;4&quot; &#125;] 注意：Kubernetes 不需要了解 dongle 资源的含义和用途。 前面的 PATCH 请求告诉 Kubernetes 你的节点拥有四个你称之为 dongle 的东西。 启动一个代理（proxy），以便你可以很容易地向 Kubernetes API server 发送请求： kubectl proxy 在另一个命令窗口中，发送 HTTP PATCH 请求。 用你的节点名称替换 &lt;your-node-name&gt;： curl --header &quot;Content-Type: application/json-patch+json&quot; \\ --request PATCH \\ --data &#x27;[&#123;&quot;op&quot;: &quot;add&quot;, &quot;path&quot;: &quot;/status/capacity/example.com~1dongle&quot;, &quot;value&quot;: &quot;4&quot;&#125;]&#x27; \\ http://localhost:8001/api/v1/nodes/&lt;your-node-name&gt;/status 说明： 在前面的请求中，~1 为 patch 路径中 “/” 符号的编码。 JSON-Patch 中的操作路径值被解析为 JSON 指针。 kubectl describe node &lt;your-node-name&gt; 清理扩展资源这里是一个从节点移除 dongle 资源发布的 PATCH 请求。 PATCH /api/v1/nodes/&lt;your-node-name&gt;/status HTTP/1.1Accept: application/jsonContent-Type: application/json-patch+jsonHost: k8s-master:8080[ &#123; &quot;op&quot;: &quot;remove&quot;, &quot;path&quot;: &quot;/status/capacity/example.com~1dongle&quot;, &#125;] 启动一个代理，以便你可以很容易地向 Kubernetes API 服务器发送请求： kubectl proxy 在另一个命令窗口中，发送 HTTP PATCH 请求。用你的节点名称替换 &lt;your-node-name&gt;： curl --header &quot;Content-Type: application/json-patch+json&quot; \\--request PATCH \\--data &#x27;[&#123;&quot;op&quot;: &quot;remove&quot;, &quot;path&quot;: &quot;/status/capacity/example.com~1dongle&quot;&#125;]&#x27; \\http://localhost:8001/api/v1/nodes/&lt;your-node-name&gt;/status 验证 dongle 资源的发布已经被移除： kubectl describe node &lt;your-node-name&gt; | grep dongle (你应该看不到任何输出) Device Plugins官方链接：https://kubernetes.io/zh-cn/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/ 特性状态： Kubernetes v1.10 [beta] Kubernetes 提供了一个 设备插件框架， 你可以用它来将系统硬件资源发布到 Kubelet。 供应商可以实现设备插件，由你手动部署或作为 DaemonSet 来部署，而不必定制 Kubernetes 本身的代码。目标设备包括 GPU、高性能 NIC、FPGA、 InfiniBand 适配器以及其他类似的、可能需要特定于供应商的初始化和设置的计算资源。 工作机制介绍一下 Device Plugin 的工作机制，整个 Device Plugin 的工作流程可以分成两个部分： 一个是启动时刻的资源上报； 另一个是用户使用时刻的调度和运行。","categories":[{"name":"device-plugins","slug":"device-plugins","permalink":"http://lizhewei91.github.io/categories/device-plugins/"}],"tags":[{"name":"kubernetnes","slug":"kubernetnes","permalink":"http://lizhewei91.github.io/tags/kubernetnes/"},{"name":"device-plugins","slug":"device-plugins","permalink":"http://lizhewei91.github.io/tags/device-plugins/"}]},{"title":"hexo+typora图片插入","slug":"hexo-typora-photos","date":"2022-11-28T14:46:29.000Z","updated":"2022-11-28T14:52:49.556Z","comments":true,"path":"2022/11/28/29/","link":"","permalink":"http://lizhewei91.github.io/2022/11/28/29/","excerpt":"","text":"Typora设置。点击文件-&gt;偏好设置-&gt;图像，配置插入图片问复制到指定路径，底下三个勾都选，如下图所示。 Hexo配置。在根目录下，进入bash命令框，输入npm install hexo-image-link --save安装插件。 更改根目录下_config.yml配置，找到post_asset_folder，改为true。 写文章前，在根目录bash命令框中输入hexo new 文章题目，可以自动在post文件夹中生成文章题目.md与文章题目图片存储目录了。 这样就配置成功了。写文章之前，现在你可以把图片像word编辑一样拖动到typora直接预览，该过程不需要输入什么图片插入指令呀存储路径呀啥的，也不需要专门去对图片进行转存；直接网页端预览，图片可以正常显示。","categories":[{"name":"hexo","slug":"hexo","permalink":"http://lizhewei91.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://lizhewei91.github.io/tags/hexo/"}]},{"title":"性能剖析大杀器 pprof","slug":"golang-pprof","date":"2022-11-28T12:28:56.000Z","updated":"2022-11-28T14:56:05.163Z","comments":true,"path":"2022/11/28/56/","link":"","permalink":"http://lizhewei91.github.io/2022/11/28/56/","excerpt":"","text":"pprof在 Go 语言中，PProf 是用于可视化和分析性能分析数据的工具，pprof 以 profile.proto 读取分析样本的集合，并生成报告以可视化并帮助分析数据（支持文本和图形报告）。 而刚刚提到的 profile.proto 是一个 Protobuf v3 的描述文件，它描述了一组 callstack 和 symbolization 信息， 作用是统计分析的一组采样的调用栈，是很常见的 stacktrace 配置文件格式。 可以做什么 CPU Profiling：CPU 分析，按照一定的频率采集所监听的应用程序 CPU（含寄存器）的使用情况，可确定应用程序在主动消耗 CPU 周期时花费时间的位置。 Memory Profiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。 Block Profiling：阻塞分析，记录Goroutine阻塞等待同步（包括定时器通道）的位置，默认不开启，需要调用 runtime.SetBlockProfileRate进行设置。 Mutex Profiling：互斥锁分析，报告互斥锁的竞争情况，默认不开启，需要调用 runtime.SetMutexProfileFraction 进行设置。 Goroutine Profiling：Goroutine 分析，可以对当前应用程序正在运行的 Goroutine 进行堆栈跟踪和分析。 其中像是 Goroutine Profiling 这项功能会在实际排查中会经常用到。因为很多问题出现时的表象就是 Goroutine 暴增，而这时候我们要做的事情之一就是查看应用程序中的 Goroutine 正在做什么事情，因为什么阻塞了，然后再进行下一步。 采样方式 runtime/pprof：采集程序（非 Server）的指定区块的运行数据进行分析。 net/http/pprof：基于HTTP Server运行，并且可以采集运行时数据进行分析。 go test：通过运行测试用例，并指定所需标识来进行采集。 使用模式 Report generation：报告生成。 Interactive terminal use：交互式终端使用。 Web interface：Web 界面。 服务型应用如果你的应用程序是一直运行的，比如 web 应用，那么可以使用net/http/pprof库，它能够在提供 HTTP 服务进行分析。 如果使用了默认的 http.DefaultServeMux（通常是代码直接使用 http.ListenAndServe(“0.0.0.0:8080”, nil)），只需要在你的web server端代码中按如下方式导入net/http/pprof import _ &quot;net/http/pprof&quot; 为什么要初始化net/http/pprof在我们的例子中，你会发现我们在引用上对 net/http/pprof包进行了默认的初始化（也就是 _），如果你曾经漏了，或者没加，你会发现压根调用不了 pprof 的相关接口，这是为什么呢，我们一起看看下面该包的初始化方法，如下： func init() &#123; http.HandleFunc(&quot;/debug/pprof/&quot;, Index) http.HandleFunc(&quot;/debug/pprof/cmdline&quot;, Cmdline) http.HandleFunc(&quot;/debug/pprof/profile&quot;, Profile) http.HandleFunc(&quot;/debug/pprof/symbol&quot;, Symbol) http.HandleFunc(&quot;/debug/pprof/trace&quot;, Trace)&#125; 实际上 net/http/pprof会在初始化函数中对标准库中net/http所默认提供的 DefaultServeMux 进行路由注册，源码如下： var DefaultServeMux = &amp;defaultServeMuxvar defaultServeMux ServeMuxfunc HandleFunc(pattern string, handler func(ResponseWriter, *Request)) &#123; DefaultServeMux.HandleFunc(pattern, handler)&#125; 而我们在例子中使用的 HTTP Server，也是使用的标准库中默认提供的，因此便完美的结合在了一起，这也恰好也是最小示例的模式。 这时候你可能会注意到另外一个问题，那就是我们的实际项目中，都是有相对独立的 ServeMux 的，这时候我们只要仿照着将 pprof 对应的路由注册进去就好了，如下： mux := http.NewServeMux()mux.HandleFunc(&quot;/debug/pprof/&quot;, pprof.Index)mux.HandleFunc(&quot;/debug/pprof/cmdline&quot;, pprof.Cmdline)mux.HandleFunc(&quot;/debug/pprof/profile&quot;, pprof.Profile)mux.HandleFunc(&quot;/debug/pprof/symbol&quot;, pprof.Symbol)mux.HandleFunc(&quot;/debug/pprof/trace&quot;, pprof.Trace) 如果你使用的是gin框架，那么推荐使用 github.com/gin-contrib/pprof，在代码中通过以下命令注册 pprof 相关路由。 pprof.Register(router) 一个简单的例子package mainimport ( &quot;log&quot; &quot;net/http&quot; _ &quot;net/http/pprof&quot; &quot;time&quot;)var datas []stringfunc main() &#123; str := &quot;hello,world&quot; go func() &#123; for &#123; log.Printf(&quot;len:%d\\n&quot;, Add(str)) time.Sleep(10 * time.Millisecond) &#125; &#125;() _ = http.ListenAndServe(&quot;0.0.0.0:8080&quot;, nil)&#125;func Add(str string) int &#123; datas = append(datas, str) return len(datas)&#125; 接下来我们运行这个程序，访问 http://127.0.0.1:6060/debug/pprof/ 地址，检查是否正常响应。 通过浏览器访问第一种方式，我们可以直接通过浏览器，进行查看，那么在第一步我们可以先查看总览页面，也就是访问 http://127.0.0.1:8080/debug/pprof/，如下： /debug/pprof/Types of profiles available:Count Profile3 allocs0 block0 cmdline5 goroutine3 heap0 mutex0 profile8 threadcreate0 tracefull goroutine stack dump allocs：查看过去所有内存分配的样本，访问路径为$HOST/debug/pprof/allocs。 block：查看导致阻塞同步的堆栈跟踪，访问路径为$HOST/debug/pprof/block。 cmdline：当前程序的命令行的完整调用路径。 goroutine：查看当前所有运行的 goroutines 堆栈跟踪，访问路径为$HOST/debug/pprof/goroutine。 heap：查看活动对象的内存分配情况， 访问路径为$HOST/debug/pprof/heap。 mutex：查看导致互斥锁的竞争持有者的堆栈跟踪，访问路径为$HOST/debug/pprof/mutex。 profile：默认进行 30s 的 CPU Profiling，得到一个分析用的 profile 文件，访问路径为$HOST/debug/pprof/profile。 threadcreate：查看创建新OS线程的堆栈跟踪，访问路径为$HOST/debug/pprof/threadcreate。 如果在相应的路径上加“?debug=1”，则可以直接在浏览器中访问，如图所示： 若不新增debug参数，则会直接下载对应的profile文件。 注意：debug的访问方式具有时效性，在实际场景中，我们通常将profile文件保存下来，便于二次分析。 通过交互式终端使用CPU Profiling第二种方式，我们可以直接通过命令行，来完成对正在运行的应用程序 pprof 的抓取和分析。 $ go tool pprof http://localhost:8080/debug/pprof/profile?seconds=60Fetching profile over HTTP from http://localhost:6060/debug/pprof/profile?seconds=60Saved profile in /Users/eddycjy/pprof/pprof.samples.cpu.002.pb.gzType: cpuDuration: 1mins, Total samples = 37.25s (61.97%)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) 执行该命令后，需等待 60 秒（可调整 seconds 的值），pprof 会进行 CPU Profiling，结束后将默认进入 pprof 的命令行交互式模式，可以对分析的结果进行查看或导出。另外如果你所启动的 HTTP Server 是 TLS 的方式，那么在调用go tool pprof 时，需要将调用路径改为：go tool pprof https+insecure://localhost:8080/debug/pprof/profile\\?seconds\\=60。 (pprof) top10Showing nodes accounting for 1.38s, 100% of 1.38s totalShowing top 10 nodes out of 50 flat flat% sum% cum cum% 0.60s 43.48% 43.48% 0.80s 57.97% runtime.kevent 0.31s 22.46% 65.94% 0.31s 22.46% runtime.libcCall 0.21s 15.22% 81.16% 0.22s 15.94% syscall.syscall 0.15s 10.87% 92.03% 0.26s 18.84% runtime.pthread_cond_wait 0.04s 2.90% 94.93% 0.04s 2.90% runtime.pthread_cond_signal 0.02s 1.45% 96.38% 0.02s 1.45% runtime.walltime 0.02s 1.45% 97.83% 0.02s 1.45% runtime.write1 0.01s 0.72% 98.55% 0.01s 0.72% log.itoa 0.01s 0.72% 99.28% 0.01s 0.72% runtime.(*mcache).prepareForSweep 0.01s 0.72% 100% 0.01s 0.72% runtime.memmove flat：函数自身的运行耗时。 flat%：函数自身在 CPU 运行耗时总比例。 sum%：函数自身累积使用 CPU 总比例。 cum：函数自身及其调用函数的运行总耗时。 cum%：函数自身及其调用函数的运行耗时总比例。 Name：函数名。 在大多数的情况下，我们可以通过这五列得出一个应用程序的运行情况，知道当前是什么函数，正在做什么事情，占用了多少资源，谁又是占用资源的大头，以此来得到一个初步的分析方向。 另外在交互命令行中，pprof 还支持了大量的其它命令，具体可执行 pprof help 查看帮助说明。 Heap Profiling$ go tool pprof http://localhost:8080/debug/pprof/heapFetching profile over HTTP from http://localhost:8080/debug/pprof/heapSaved profile in /Users/lizhewei/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.001.pb.gzType: inuse_spaceTime: Dec 15, 2021 at 4:56pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) 执行该命令后，能够很快的拉取到其结果，因为它不需要像 CPU Profiling 做采样等待，这里需要注意的一点是 Type 这一个选项，你可以看到它默认显示的是 inuse_space，实际上可以针对多种内存概况进行分析，常用的类别如下： 一共有四种类型： inuse_space：分析应用程序的常驻内存占用情况。 alloc_objects：分析应用程序的内存临时分配情况。 inuse_objects：查看每个函数所分别的对象数量。 alloc_space：查看分配的内存空间大小。 inuse_space：分析应用程序的常驻内存占用情况。 $ go tool pprof -inuse_space http://localhost:8080/debug/pprof/heapFetching profile over HTTP from http://localhost:8080/debug/pprof/heapSaved profile in /Users/lizhewei/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.002.pb.gzType: inuse_spaceTime: Dec 15, 2021 at 4:59pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) topShowing nodes accounting for 4130.49kB, 100% of 4130.49kB totalShowing top 10 nodes out of 20 flat flat% sum% cum cum% 1567.04kB 37.94% 37.94% 1567.04kB 37.94% main.Add (inline) 1537.69kB 37.23% 75.17% 1537.69kB 37.23% runtime.allocm 513.56kB 12.43% 87.60% 513.56kB 12.43% regexp/syntax.init 512.20kB 12.40% 100% 512.20kB 12.40% runtime.malg 0 0% 100% 1567.04kB 37.94% main.main.func1 alloc_objects：分析应用程序的内存临时分配情况。 $ go tool pprof -alloc_objects http://localhost:8080/debug/pprof/heapFetching profile over HTTP from http://localhost:8080/debug/pprof/heapSaved profile in /Users/lizhewei/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.003.pb.gzType: alloc_objectsTime: Dec 15, 2021 at 5:01pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) topShowing nodes accounting for 311313, 99.07% of 314251 totalDropped 39 nodes (cum &lt;= 1571) flat flat% sum% cum cum% 163842 52.14% 52.14% 311313 99.07% main.main.func1 131074 41.71% 93.85% 131074 41.71% fmt.Sprintf 16397 5.22% 99.07% 16397 5.22% main.Add (inline) 0 0% 99.07% 131074 41.71% log.Printf 另外还有 inuse_objects 和 alloc_space 类别，分别对应查看每个函数所分别的对象数量和查看分配的内存空间大小，具体可根据情况选用。 Goroutine Profiling$ go tool pprof http://localhost:8080/debug/pprof/goroutineFetching profile over HTTP from http://localhost:8080/debug/pprof/goroutineSaved profile in /Users/lizhewei/pprof/pprof.goroutine.001.pb.gzType: goroutineTime: Dec 15, 2021 at 5:04pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) 在查看 goroutine 时，我们可以使用 traces 命令，这个命令会打印出对应的所有调用栈，以及指标信息，可以让我们很便捷的查看到整个调用链路有什么，分别在哪里使用了多少个 goroutine，并且能够通过分析查看到谁才是真正的调用方，输出结果如下： (pprof) tracesType: goroutine-----------+------------------------------------------------------- 2 runtime.gopark runtime.netpollblock internal/poll.runtime_pollWait ...-----------+------------------------------------------------------- 1 runtime.gopark runtime.netpollblock ... net/http.ListenAndServe main.main runtime.main 在调用栈上来讲，其展示顺序是自下而上的，也就是 runtime.main 方法调用了 main.main 方法，main.main 方法又调用了 net/http.ListenAndServe 方法，这里对应的也就是我们所使用的示例代码了，排查起来会非常方便。 每个调用堆栈信息用 ----------- 分割，函数方法前的就是指标数据，像 Goroutine Profiling 展示是就是该方法占用的 goroutine 的数量。而 Heap Profiling 展示的就是占用的内存大小，如下： $ go tool pprof http://localhost:8080/debug/pprof/heap...Type: inuse_spaceEntering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) tracesType: inuse_space-----------+------------------------------------------------------- bytes: 13.55MB 13.55MB main.Add main.main.func1-----------+------------------------------------------------------- Mutex Profiling怎么样的情况下会造成阻塞呢，一般有如下方式：调用 chan（通道）、调用 sync.Mutex （同步锁）、调用 time.Sleep() 等等。那么为了验证互斥锁的竞争持有者的堆栈跟踪，我们可以根据以上的 sync.Mutex 方式，来调整先前的示例代码，代码如下： func init() &#123; runtime.SetMutexProfileFraction(1)&#125;func main() &#123; var m sync.Mutex var datas = make(map[int]struct&#123;&#125;) for i := 0; i &lt; 999; i++ &#123; go func(i int) &#123; m.Lock() defer m.Unlock() datas[i] = struct&#123;&#125;&#123;&#125; &#125;(i) &#125; _ = http.ListenAndServe(&quot;:6061&quot;, nil)&#125; 需要特别注意的是 runtime.SetMutexProfileFraction 语句，如果未来希望进行互斥锁的采集，那么需要通过调用该方法来设置采集频率，若不设置或没有设置大于 0 的数值，默认是不进行采集的。 接下来我们进行调用 go tool pprof 进行分析，如下： $ go tool pprof http://localhost:8081/debug/pprof/mutexFetching profile over HTTP from http://localhost:8081/debug/pprof/mutexSaved profile in /Users/lizhewei/pprof/pprof.contentions.delay.002.pb.gzType: delayTime: Dec 15, 2021 at 5:18pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) 我们查看调用 top 命令，查看互斥量的排名： (pprof) topShowing nodes accounting for 1.77ms, 100% of 1.77ms total flat flat% sum% cum cum% 1.77ms 100% 100% 1.77ms 100% sync.(*Mutex).Unlock 0 0% 100% 1.77ms 100% main.main.func1 接下来我们可以调用 list 命令，看到指定函数的代码情况（包含特定的指标信息，例如：耗时），若函数名不明确，默认会对函数名进行模糊匹配，如下： (pprof) list mainTotal: 1.77msROUTINE ======================== main.main.func1 in /Volumes/D/go/src/github.com/lizw91/pprof/main.go 0 1.77ms (flat, cum) 100% of Total . . 17: for i := 0; i &lt; 1000; i++ &#123; . . 18: go func(i int) &#123; . . 19: m.Lock() . . 20: defer m.Unlock() . . 21: datas[i] = struct&#123;&#125;&#123;&#125; . 1.77ms 22: &#125;(i) . . 23: &#125; . . 24: . . 25: _ = http.ListenAndServe(&quot;:8081&quot;, nil) . . 26:&#125; 我们可以在输出的分析中比较准确的看到引起互斥锁的函数在哪里，锁开销在哪里，在本例中是第 22 行。 Block Profiling与 Mutex 的 runtime.SetMutexProfileFraction 相似，Block 也需要调用 runtime.SetBlockProfileRate() 进行采集量的设置，否则默认关闭，若设置的值小于等于 0 也会认为是关闭。 与上小节 Mutex 相比，主体代码不变，仅是新增 runtime.SetBlockProfileRate()的调用，如下： 示例代码 package mainimport ( &quot;net/http&quot; _ &quot;net/http/pprof&quot; &quot;runtime&quot; &quot;sync&quot;)func init() &#123; runtime.SetBlockProfileRate(1)&#125;func main() &#123; var m sync.Mutex var datas = make(map[int]struct&#123;&#125;) for i := 0; i &lt; 1000; i++ &#123; go func(i int) &#123; m.Lock() defer m.Unlock() datas[i] = struct&#123;&#125;&#123;&#125; &#125;(i) &#125; _ = http.ListenAndServe(&quot;:8081&quot;, nil)&#125; 我们查看调用 top 命令，查看阻塞情况的排名： $ go tool pprof http://localhost:8081/debug/pprof/blockFetching profile over HTTP from http://localhost:8081/debug/pprof/blockSaved profile in /Users/lizhewei/pprof/pprof.contentions.delay.003.pb.gzType: delayTime: Dec 15, 2021 at 5:21pm (CST)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) topShowing nodes accounting for 48.97ms, 100% of 48.97ms total flat flat% sum% cum cum% 48.97ms 100% 100% 48.97ms 100% sync.(*Mutex).Lock (inline) 0 0% 100% 48.97ms 100% main.main.func1 同样的，我们也可以调用 list 命令查看具体的阻塞情况，执行方式和排查模式与先前概述的一致。 (pprof) list mainTotal: 48.97msROUTINE ======================== main.main.func1 in /Volumes/D/go/src/github.com/lizw91/pprof/main.go 0 48.97ms (flat, cum) 100% of Total . . 14:func main() &#123; . . 15: var m sync.Mutex . . 16: var datas = make(map[int]struct&#123;&#125;) . . 17: for i := 0; i &lt; 1000; i++ &#123; . . 18: go func(i int) &#123; . 48.97ms 19: m.Lock() . . 20: defer m.Unlock() . . 21: datas[i] = struct&#123;&#125;&#123;&#125; . . 22: &#125;(i) . . 23: &#125; . . 24: 查看可视化界面接下来我们继续使用前面的示例程序，将其重新运行起来，然后在其它窗口执行下述命令： // 获取 cpu 指标$ wget -O cpu.profile http://127.0.0.1:8080/debug/pprof/profile?seconds=30// 获取 heap 指标 $ wget -O mem.profile http://127.0.0.1:8080/debug/pprof/profile?seconds=30 默认需要等待 30 秒，执行完毕后可在当前目录下发现采集的文件 cpu.profile，针对可视化界面我们有两种方式可进行下一步分析： 方法一（推荐）：该命令将在所指定的端口号运行一个 pprof 的分析用的站点 $ go tool pprof -http=:8081 cpu.profile 方法二：通过 web 命令将以 svg 的文件格式写入图形，然后在 Web 浏览器中将其打开。 $ go tool pprof cpu.profileType: cpuTime: Feb 1, 2020 at 12:09pm (CST)Duration: 30s, Total samples = 60ms ( 0.2%)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) web 如果出现错误提示 Could not execute dot; may need to install graphviz.，那么意味着你需要安装 graphviz组件。 另外方法一所运行的站点，实际上包含了方法二的内容（svg图片），并且更灵活，因此非特殊情况，我们会直接使用方法一的方式运行站点来做观察和分析。 通过 pprof 所提供的可视化界面，我们能够更方便、更直观的看到 Go 应用程序的调用链、使用情况等。 另外在 View 菜单栏中，PProf 还支持多种分析方式的切换，如下： view 菜单栏 接下来我们将基于 CPU Profiling 所抓取的 Profile 进行一一介绍，而其它 Profile 类型的分析模式也是互通的，只要我们了解了一种，其余的也就会了。 Top flat：函数自身的运行耗时。 flat%：函数自身在 CPU 运行耗时总比例。 sum%：函数自身累积使用 CPU 总比例。 cum：函数自身及其调用函数的运行总耗时。 cum%：函数自身及其调用函数的运行耗时总比例。 Name：函数名。 Graph 该视图展示的为整体的函数调用流程，框越大、线越粗、框颜色越鲜艳（红色）就代表它占用的时间越久，开销越大。相反若框颜色越淡，越小则代表在整体的函数调用流程中，它的开销是相对较小的。因此我们可以用此视图去分析谁才是开销大头，它又是因为什么调用流程而被调用的。 Peek peek 栏目，此视图相较于 Top 视图，增加了所属的上下文信息的展示，也就是函数的输出调用者/被调用者。 Source source 栏目，该视图主要是增加了面向源代码的追踪和分析，可以看到其开销主要消耗在哪里。 flame graph Flame Graph（火焰图）它是可动态的，调用顺序由上到下（A -&gt; B -&gt; C -&gt; D），每一块代表一个函数、颜色越鲜艳（红）、区块越大代表占用 CPU 的时间更长。同时它也支持点击块深入进行分析。 我们选择页面上的 main.main.func1 区块，将会进入到其属下的下一层级，如下： 进一步查看 flame graph，这样子我们就可以根据不同函数的多维度层级进行分析，能够更好的观察其流转并发现问题。 工具型应用如果你的应用程序是运行一段时间就结束退出类型。那么最好的办法是在应用退出的时候把 profiling 的报告保存到文件中，进行分析。对于这种情况，可以使用runtime/pprof库。 首先在代码中导入runtime/pprof工具： import &quot;runtime/pprof&quot; CPU性能分析开启CPU性能分析： pprof.StartCPUProfile(w io.Writer) 停止CPU性能分析： pprof.StopCPUProfile() 应用执行结束后，就会生成一个文件，保存了我们的 CPU profiling 数据。得到采样数据之后，使用 go tool pprof工具进行 CPU 性能分析。 内存性能优化记录程序的堆栈信息 pprof.WriteHeapProfile(w io.Writer) go tool pprof默认是使用-inuse_space 进行统计，还可以使用 -inuse-objects 查看分配对象的数量。 示例// runtime_pprof/main.gopackage mainimport ( &quot;flag&quot; &quot;fmt&quot; &quot;os&quot; &quot;runtime/pprof&quot; &quot;time&quot;)// 一段有问题的代码func logicCode() &#123; var c chan int for &#123; select &#123; case v := &lt;-c: fmt.Printf(&quot;recv from chan, value:%v\\n&quot;, v) default: &#125; &#125;&#125;func main() &#123; var isCPUPprof bool var isMemPprof bool flag.BoolVar(&amp;isCPUPprof, &quot;cpu&quot;, false, &quot;turn cpu pprof on&quot;) flag.BoolVar(&amp;isMemPprof, &quot;mem&quot;, false, &quot;turn mem pprof on&quot;) flag.Parse() if isCPUPprof &#123; file, err := os.Create(&quot;./cpu.pprof&quot;) if err != nil &#123; fmt.Printf(&quot;create cpu pprof failed, err:%v\\n&quot;, err) return &#125; pprof.StartCPUProfile(file) defer pprof.StopCPUProfile() &#125; for i := 0; i &lt; 8; i++ &#123; go logicCode() &#125; time.Sleep(20 * time.Second) if isMemPprof &#123; file, err := os.Create(&quot;./mem.pprof&quot;) if err != nil &#123; fmt.Printf(&quot;create mem pprof failed, err:%v\\n&quot;, err) return &#125; pprof.WriteHeapProfile(file) file.Close() &#125;&#125; 通过flag我们可以在命令行控制是否开启 CPU和 Mem 的性能分析。 将上面的代码保存并编译成runtime_pprof 可执行文件，执行时加上 -cpu 命令行参数如下： go run main.go -cpu 等待30秒后会在当前目录下生成一个 cpu.pprof 文件。然后，执行go tool pprof命令就可以查看 $ go tool pprof cpu.pprofType: cpuTime: Dec 15, 2021 at 8:25pm (CST)Duration: 20.19s, Total samples = 119.64s (592.65%)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) topShowing nodes accounting for 119.62s, 100% of 119.64s totalDropped 2 nodes (cum &lt;= 0.60s) flat flat% sum% cum cum% 52.65s 44.01% 44.01% 52.65s 44.01% runtime.chanrecv 51.04s 42.66% 86.67% 103.69s 86.67% runtime.selectnbrecv 15.93s 13.31% 100% 119.63s 100% main.logicCode 压测工具wrk推荐使用： https://github.com/wg/wrk https://github.com/adjust/go-wrk 使用wrk进行压测: go-wrk -n 50000 http://127.0.0.1:8080/book/list 在上面压测进行的同时，打开另一个终端执行: $ go tool pprof http://localhost:8080/debug/pprof/profile\\?seconds\\=60 pprof与性能测试结合go test 命令有两个参数和 pprof 相关，它们分别指定生成的 CPU 和 Memory profiling 保存的文件： -cpuprofile：cpu profiling 数据要保存的文件地址 -memprofile：memory profiling 数据要报文的文件地址 我们还可以选择将pprof与性能测试相结合，比如： 比如下面执行测试的同时，也会执行 CPU profiling，并把结果保存在 cpu.prof 文件中： go test -bench . -cpuprofile=cpu.profile 比如下面执行测试的同时，也会执行 Mem profiling，并把结果保存在 cpu.prof 文件中： go test -bench . -memprofile=./mem.profile 注意： 获取的 Profiling 数据是动态的，要想获得有效的数据，请保证应用处于较大的负载（比如正在生成中运行的服务，或者通过其他工具模拟访问压力）。否则如果应用处于空闲状态，得到的结果可能没有任何意义。所以，Profiling 一般和性能测试一起使用","categories":[{"name":"pprof","slug":"pprof","permalink":"http://lizhewei91.github.io/categories/pprof/"}],"tags":[{"name":"pprof","slug":"pprof","permalink":"http://lizhewei91.github.io/tags/pprof/"},{"name":"性能分析","slug":"性能分析","permalink":"http://lizhewei91.github.io/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"name":"golang","slug":"golang","permalink":"http://lizhewei91.github.io/tags/golang/"}]}],"categories":[{"name":"device-plugins","slug":"device-plugins","permalink":"http://lizhewei91.github.io/categories/device-plugins/"},{"name":"hexo","slug":"hexo","permalink":"http://lizhewei91.github.io/categories/hexo/"},{"name":"pprof","slug":"pprof","permalink":"http://lizhewei91.github.io/categories/pprof/"}],"tags":[{"name":"kubernetnes","slug":"kubernetnes","permalink":"http://lizhewei91.github.io/tags/kubernetnes/"},{"name":"device-plugins","slug":"device-plugins","permalink":"http://lizhewei91.github.io/tags/device-plugins/"},{"name":"hexo","slug":"hexo","permalink":"http://lizhewei91.github.io/tags/hexo/"},{"name":"pprof","slug":"pprof","permalink":"http://lizhewei91.github.io/tags/pprof/"},{"name":"性能分析","slug":"性能分析","permalink":"http://lizhewei91.github.io/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"name":"golang","slug":"golang","permalink":"http://lizhewei91.github.io/tags/golang/"}]}